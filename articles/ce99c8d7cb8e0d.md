---
title: "XGenã‚’è©¦ã™"
emoji: "ğŸ¦”"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [python, AI, LLM]
published: false
---

# XGenã¨ã¯
SalesforceãŒé–‹ç™ºã—ãŸ7Bã®LLMã§ã™ã€‚ç‰¹å¾´ã¨ã—ã¦ã€æœ€å¤§8Kã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ãƒ»æœ€å¤§1.5Tãƒˆãƒ¼ã‚¯ãƒ³ã§è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚

* æ¨™æº–çš„ãªNLPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦ã€XGenã¯åŒç¨‹åº¦ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMï¼ˆMPTã€Falconã€LLaMAã€Redpajamaã€OpenLLaMAãªã©ï¼‰ã¨æ¯”è¼ƒã—ãŸå ´åˆã«åŒç­‰ä»¥ä¸Šã®çµæœã‚’é”æˆ

https://blog.salesforceairesearch.com/xgen/


# XGenã‚’å‹•ã‹ã™

HuggingFace Hubã«ã¯ã€3ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚

* [XGen-7B-4K-Base with support for 4K sequence length](https://huggingface.co/Salesforce/xgen-7b-4k-base)
* [XGen-7B-8K-Base with support for 8K sequence length](https://huggingface.co/Salesforce/xgen-7b-8k-base)
* [XGen-7B-8k-Inst with instruction-finetuning](https://huggingface.co/Salesforce/xgen-7b-8k-inst) â€» ç ”ç©¶é–‹ç™ºç›®çš„ã«åˆ©ç”¨å¯èƒ½


https://github.com/salesforce/xGen

## xgenã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³

xgenã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¦ãã¾ã™ã€‚ä»Šå›ã¯Macã®ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ã‹ã—ã¾ã™ã€‚
ä»®æƒ³ç’°å¢ƒã¯venvã§ä½œæˆã—ã€`source`ã‚³ãƒãƒ³ãƒ‰ã§activateã—ã¾ã™ã€‚

```zsh
python -m venv .venv
source .venv/bin/activate
git clone git@github.com:salesforce/xgen.git
```

ç¶šã„ã¦ã€`requirements.txt`ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```zsh
pip install -r requirements.txt 
```


## OpenAI Tittokenãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install tiktoken
```

tittokenã¯ã€OpenAIã®ãƒ¢ãƒ‡ãƒ«ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã®é«˜é€ŸãªBPEãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§ã™ã€‚

https://github.com/openai/tiktoken



## å‹•ã‹ã™

xgenã®ãƒªãƒã‚¸ãƒˆãƒªã‚’cloneã™ã‚‹ã¨ã€`sample.py`ã«åŒæ§˜ã®ã‚³ãƒ¼ãƒ‰ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã¡ã‚‰ã‚’åˆ©ç”¨ã™ã‚‹ã¨è‰¯ã„ã§ã™ã€‚

ã‚³ãƒ¼ãƒ‰ã®ä¸­èº«ã¯ä»¥ä¸‹ã§ã™ã€‚

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(
    "Salesforce/xgen-7b-8k-base",
    trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    "Salesforce/xgen-7b-8k-base",
    torch_dtype=torch.bfloat16)
inputs = tokenizer("The world is", return_tensors="pt")
sample = model.generate(**inputs, max_length=128)
print(tokenizer.decode(sample[0]))
```

ç§ã®ç’°å¢ƒã ã¨ã€PyTorchã‚’å…¥ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸã€‚
```
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
```

å®Ÿè¡Œã—ã¾ã™ã€‚

```
python sample.py
```

ã“ã“ã§ãã¡ã‚“ã¨å‹•ä½œã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ãªã©ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå§‹ã¾ã‚Šã€çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
ãªã‚“ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ãªçµæœãŒã§ã¾ã—ãŸã€‚

```
The world is full of people who are not happy with their lives. They are not happy with their jobs, their relationships, their families, their friends, their health, their finances, their appearance, their pasts, their futures, their choices, their lives. They are not happy with anything.

They are not happy with themselves.

They are not happy with the world.

They are not happy with the universe.

They are not happy with the cosmos.

They are not happy with the cosmos.

They are not happy with the cosmos.

They are not happy with the cosmos
```

ä»–ã«ã‚‚èã„ã¦ã¿ã¾ã™ã€‚tokenizerã®éƒ¨åˆ†ã‚’`Where is the capital of Japan?`ã«ã—ã¾ã—ãŸã€‚
```
Tokyo is a major transportation hub, with a large number of airports, train stations,
# æ±äº¬ã¯äº¤é€šã®è¦æ‰€ã§ã‚ã‚Šã€å¤šãã®ç©ºæ¸¯ã‚„é§…ãŒã‚ã‚‹ã€
```


## ã‚¨ãƒ©ãƒ¼ã®åˆ‡ã‚Šåˆ†ã‘

ç§ã®ç’°å¢ƒã§ã¯ã€sample.pyã‚’å‹•ã‹ã™ã¨ãã«ã€ã‚¨ãƒ©ãƒ¼`KeyError: 'llama'`ãŒã§ã¾ã—ãŸã€‚
èª¿æŸ»ã®çµæœã€`pip install git+https://github.com/zphang/transformers@llama_push`ã‚’è©¦ã™ã¨å‹•ä½œã—ã¾ã—ãŸã€‚

```
pip install git+https://github.com/zphang/transformers@llama_push
```

https://huggingface.co/decapoda-research/llama-7b-hf/discussions/3#6425f70fb9dfed28cf6473c3

ã“ã®çµæœã€transformersã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯`4.27.0.dev0`ã¨ãªã‚Šã¾ã—ãŸã€‚
åˆ‡ã‚Šåˆ†ã‘ã§ã¯`4.31.0.dev0`ã‚‚è©¦ã—ã¾ã—ãŸãŒã€å‹•ä½œã—ã¾ã›ã‚“ã§ã—ãŸã€‚